{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar importação de planilhas, instalar todas as dependencias que constam no arquivo 'requirements.txt', onde:<br>\n",
    "pandas - biblioteca que realiza leitura e modela as planilhas<br>\n",
    "sqlalchemy - biblioteca de banco de dados<br>\n",
    "psycopg2 - biblioteca complementar de banco de dados postgresql<br>\n",
    "sshtunnel - estabelece tunel de conexão com servidor via vpn<br>\n",
    "obs: necessário estar conectado via vpn com banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importação de planilhas\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria o tunel de conexao ssh com o servidor\n",
    "tunnel = SSHTunnelForwarder(\n",
    "    ('143.54.25.131', 22),\n",
    "    ssh_username=\"atlas-oportunidades-srv01\",\n",
    "    ssh_password = \"Mt0c5P!lzT\",\n",
    "    remote_bind_address=('localhost', 5432),\n",
    "    local_bind_address=('localhost',8000), # could be any available port\n",
    ")\n",
    "# inicializacao do tunel\n",
    "tunnel.start()\n",
    "\n",
    "#declaracao de variavel de conexao com banco de dados\n",
    "conn = create_engine(f'postgresql://atlas_adm:123456@{tunnel.local_bind_host}:{tunnel.local_bind_port}/atlasdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realiza a leitura da planilha de dados e salva em um dataframe\n",
    "df = pd.read_excel(\"./Data/_State/Data/Dados - N3.xlsx\")\n",
    "#porem mantem apenas essas duas colunas\n",
    "colunas_manter = ['code', 'name']\n",
    "df = df.loc[:, colunas_manter]\n",
    "#renomeia as colunas para as colunas de acordo com tabela tb_estados\n",
    "df = df.rename(columns={'code': 'cd_estado', 'name': 'nm_estado'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicia conexao com banco de dados e envia os dados para o servidor\n",
    "dbConnection = conn.connect()\n",
    "df.to_sql(    \n",
    "    \"tb_estados\",\n",
    "    dbConnection,\n",
    "    schema=\"atlas_schema\",\n",
    "    if_exists='replace',\n",
    "    index = False\n",
    ")\n",
    "dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza a leitura das tabelas agencia, unidades, formato e classificacao\n",
    "# salva em dataframes para comparações \n",
    "dbConnection = conn.connect()\n",
    "df_agencia = pd.read_sql(\"select * from atlas_schema.tb_agencias\", dbConnection)\n",
    "df_unidade = pd.read_sql(\"select * from atlas_schema.tb_unidades\", dbConnection)\n",
    "df_formato = pd.read_sql(\"select * from atlas_schema.tb_formato\", dbConnection)\n",
    "df_classificacao = pd.read_sql(\"select * from atlas_schema.tb_classificacao\", dbConnection)\n",
    "dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza a leitura da planilha de dicionario de estados\n",
    "# mantem só algumas colunas\n",
    "df = pd.read_excel(\"./Data/_State/dictionary_state.xlsx\")\n",
    "colunas_manter = ['Agency', 'Name', 'Description', 'Descrição', 'Label', 'Rótulo', 'Unit of analysis', 'Format', 'Classificação']\n",
    "df = df.loc[:, colunas_manter]\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        'Name': 'cd_nm_coluna', \n",
    "        'Agency': 'nm_agencia',\n",
    "        'Description': 'nm_descricao_en', \n",
    "        'Descrição': 'nm_descricao_pt', \n",
    "        'Label': 'nm_label_en', \n",
    "        'Rótulo': 'nm_label_pt', \n",
    "        'Unit of analysis': 'nm_unidade', \n",
    "        'Format': 'nm_formato', \n",
    "        'Classificação': 'nm_classificacao_pt'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a partir da leitura das tabelas de agencia, unidade, formato e classificacao em um dos blocos anteriores\n",
    "# é feito o merge no dataframe atual para assim obter a chave id das mesmas na tabela de dicionario\n",
    "df_final = pd.merge(df, df_agencia, on='nm_agencia', how='left')\n",
    "df_final = pd.merge(df_final, df_unidade, on='nm_unidade', how='left')\n",
    "df_final = pd.merge(df_final, df_formato, on='nm_formato', how='left')\n",
    "df_final = pd.merge(df_final, df_classificacao, on='nm_classificacao_pt', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uma vez que o merhe foi feito não é necessário algumas colunas pois já existem nas tabelas agencia, unidade, formato e classificacao\n",
    "# então é feito a exclusão\n",
    "colunas_manter = ['cd_nm_coluna', 'nm_descricao_en', 'nm_descricao_pt', 'nm_label_en', 'nm_label_pt', 'cd_agencia', 'cd_unidade', 'cd_formato', 'cd_classificacao']\n",
    "df_final = df_final.loc[:, colunas_manter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# após realizar todos os ajustes, os dados são salvos no banco de dados\n",
    "dbConnection = conn.connect()\n",
    "df_final.to_sql(    \n",
    "    \"tb_dicionario\",\n",
    "    dbConnection,\n",
    "    schema=\"atlas_schema\",\n",
    "    if_exists='append',\n",
    "    index = False\n",
    ")\n",
    "dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciando leitura da planilha de dados N3\n",
    "df = pd.read_excel(\"./Data/_State/Data/Dados - N3.xlsx\")\n",
    "# excluindo coluna de nome 'name'\n",
    "df = df.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as colunas são transformadas em dados\n",
    "# como um pivot table\n",
    "df1 = df.melt(\n",
    "    id_vars=['code'],\n",
    "    var_name='cd_nm_coluna',\n",
    "    value_name='vl_por_cd'\n",
    ").sort_values(by='code')\n",
    "\n",
    "# coluna renomeada\n",
    "df1 = df1.rename(columns={'code':'cd_estado'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apos modelagem dos dados é feito o envio para banco de dados\n",
    "dbConnection = conn.connect()\n",
    "df1.to_sql(    \n",
    "    \"tb_cod_valor_estado\",\n",
    "    dbConnection,\n",
    "    schema=\"atlas_schema\",\n",
    "    if_exists='append',\n",
    "    index = False\n",
    ")\n",
    "dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciando leitura da planilha de dados IPEA\n",
    "df = pd.read_excel(\"./Data/_State/Data/IPEA - Dados Estaduais.xlsx\")\n",
    "\n",
    "# excluindo coluna de nome 'name'\n",
    "df = df.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as colunas são transformadas em dados\n",
    "# como um pivot table\n",
    "df1 = df.melt(\n",
    "    id_vars=['code'],\n",
    "    var_name='cd_nm_coluna',\n",
    "    value_name='vl_por_cd'\n",
    ").sort_values(by='code')\n",
    "\n",
    "# coluna renomeada\n",
    "df1 = df1.rename(columns={'code':'cd_estado'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apos modelagem dos dados é feito o envio para banco de dados\n",
    "dbConnection = conn.connect()\n",
    "df1.to_sql(    \n",
    "    \"tb_cod_valor_estado\",\n",
    "    dbConnection,\n",
    "    schema=\"atlas_schema\",\n",
    "    if_exists='append',\n",
    "    index = False\n",
    ")\n",
    "dbConnection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
